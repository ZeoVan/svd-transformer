{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Transformers!\n",
    "\n",
    "### Attention is all you need \n",
    "(https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "### For software vulnerability detection GYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a minimal example of this **CRAZY** idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.optim import SGD,Adam\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load playset dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('playset(0.25.2).pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93792</th>\n",
       "      <td>go_file_opener_open (GOFileOpener const *fo, g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79770</th>\n",
       "      <td>updatePathMap(bool left_level) {\\n\\tPoint from...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66999</th>\n",
       "      <td>interpret_tilde(const char* path) {\\n    stati...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44284</th>\n",
       "      <td>checkVarExp(\\n        Absyn *node,\\n        Ta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49515</th>\n",
       "      <td>will_have_skip_worktree(const struct cache_ent...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96701</th>\n",
       "      <td>AVLTree_insert(AVLTree * tree, void * data)\\n{...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67815</th>\n",
       "      <td>remove_hook(const char *name, hookfn fn)\\n{\\n\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88363</th>\n",
       "      <td>output_def(dico_stream_t str, struct gcide_db ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65929</th>\n",
       "      <td>getState(\\n\\t\\tFLMUINT\\t\\tuiFieldID)\\n\\t{\\n\\t\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16426</th>\n",
       "      <td>untag_proplist(Pulse_Tag *tag, Eina_Hash **pro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          functionSource  combine\n",
       "93792  go_file_opener_open (GOFileOpener const *fo, g...    False\n",
       "79770  updatePathMap(bool left_level) {\\n\\tPoint from...    False\n",
       "66999  interpret_tilde(const char* path) {\\n    stati...    False\n",
       "44284  checkVarExp(\\n        Absyn *node,\\n        Ta...     True\n",
       "49515  will_have_skip_worktree(const struct cache_ent...     True\n",
       "...                                                  ...      ...\n",
       "96701  AVLTree_insert(AVLTree * tree, void * data)\\n{...    False\n",
       "67815  remove_hook(const char *name, hookfn fn)\\n{\\n\\...    False\n",
       "88363  output_def(dico_stream_t str, struct gcide_db ...    False\n",
       "65929  getState(\\n\\t\\tFLMUINT\\t\\tuiFieldID)\\n\\t{\\n\\t\\...    False\n",
       "16426  untag_proplist(Pulse_Tag *tag, Eina_Hash **pro...     True\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>main(int argc, char *argv[])\\n{\\n\\tchar *outfi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           functionSource combine\n",
       "count                                              100000  100000\n",
       "unique                                             100000       2\n",
       "top     main(int argc, char *argv[])\\n{\\n\\tchar *outfi...    True\n",
       "freq                                                    1   50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkCapture2() const\\n{\\n    for(int i=6;i<48;i++)\\n    {\\n        switch(board[i])\\n        {\\n        case MAN2:\\n            if(board[i+5]==MAN1 || board[i+5]==KING1)\\n                if(board[i+10]==FREE) return true;\\n            if(board[i+6]==MAN1 || board[i+6]==KING1)\\n                if(board[i+12]==FREE) return true;\\n            break;\\n        case KING2:\\n            if(board[i-6]==MAN1 || board[i-6]==KING1)\\n                if(board[i-12]==FREE) return true;\\n            if(board[i-5]==MAN1 || board[i-5]==KING1)\\n                if(board[i-10]==FREE) return true;\\n            if(board[i+5]==MAN1 || board[i+5]==KING1)\\n                if(board[i+10]==FREE) return true;\\n            if(board[i+6]==MAN1 || board[i+6]==KING1)\\n                if(board[i+12]==FREE) return true;\\n        }\\n    }\\n    return false;\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.functionSource[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data (in JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(code):\n",
    "    ## Remove newlines & tabs\n",
    "    code = re.sub('(\\n)|(\\\\\\\\n)|(\\\\\\\\)|(\\\\t)|(/)','',code)\n",
    "    ## Remove code comments\n",
    "    code = re.sub(r'/\\*(.|[\\r\\n])*?\\*/','',code)\n",
    "    ## Mix split (characters and words)\n",
    "    splitter = ' +|(;)|(\\()|(==)|(\\))|(=)|(\\+)|(\\-)|(\\[)|(\\])|(<)|(>)|({)|(#)|(\\\")'\n",
    "    code = re.split(splitter,code)\n",
    "    ## Remove None type\n",
    "    code = list(filter(None, code))\n",
    "    code = list(filter(str.strip, code))\n",
    "    ## Return list of tokens\n",
    "    return(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the codes\n",
    "dataset.functionSource = dataset.functionSource.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change labels boolean to 1 and 0\n",
    "dataset.iloc[:,1] = np.multiply(dataset.iloc[:,1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change column name\n",
    "dataset = dataset.rename(columns={'functionSource':'codes', 'combine':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "false = dataset[dataset.iloc[:,1]==0]\n",
    "true = dataset[dataset.iloc[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split to train,test,valid\n",
    "train = false[0:40000].append(true[0:40000])\n",
    "test  = false[40000:45000].append(true[40000:45000])\n",
    "valid = false[45000:50000].append(true[45000:50000])\n",
    "\n",
    "## Shuffle\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "valid = valid.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to json\n",
    "train.to_json('.data/train.json', orient='records',lines=True)\n",
    "test.to_json('.data/test.json', orient='records',lines=True)\n",
    "valid.to_json('.data/valid.json', orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the field\n",
    "\n",
    "CODES = torchtext.data.Field(batch_first=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.int64)\n",
    "fields = {'codes': ('codes', CODES), 'label': ('label', LABEL)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the data as TabularDataset\n",
    "train_data, valid_data, test_data = torchtext.data.TabularDataset.splits(\n",
    "                                        path = '.data',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'valid.json',\n",
    "                                        test = 'test.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'codes': ['camel_mime_filter_index_set_name', '(', 'CamelMimeFilterIndex', '*filter,', 'CamelIndexName', '*name', ')', '{', 'g_return_if_fail', '(', 'CAMEL_IS_MIME_FILTER_INDEX', '(', 'filter', ')', ')', ';', 'if', '(', 'name', '!', '=', 'NULL', ')', '{', 'g_return_if_fail', '(', 'CAMEL_IS_INDEX_NAME', '(', 'name', ')', ')', ';', 'g_object_ref', '(', 'name', ')', ';', '}if', '(', 'filter', '-', '>', 'priv', '-', '>', 'name', '!', '=', 'NULL', ')', 'g_object_unref', '(', 'filter', '-', '>', 'priv', '-', '>', 'name', ')', ';', 'filter', '-', '>', 'priv', '-', '>', 'name', '=', 'name', ';', '}'], 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doneeeeeeeeeeeeeeeee !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary-related preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Build the vocabulary\n",
    "\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "CODES.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 10002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(CODES.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(')', 1376013), ('(', 1375892), (';', 1270722), ('-', 656492), ('=', 633247), ('>', 507801), ('\"', 371009), ('{', 307771), ('*', 257660), ('if', 253646), ('}', 195363), ('+', 187616), ('0', 173061), ('[', 166766), (']', 166621), (',', 130888), ('return', 130564), ('i', 112319), ('==', 106834), ('1', 102418)]\n"
     ]
    }
   ],
   "source": [
    "## Most common word\n",
    "print(CODES.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', ')', '(', ';', '-', '=', '>', '\"', '{']\n",
      "defaultdict(None, {0: 0, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "print(CODES.vocab.itos[:10])\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## place into iterators\n",
    "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = 128,\n",
    "    sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init all the non important stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "#device = torch.device(\"cpu\");\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Transformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): Embedding(10002, 800)\n",
      "  (encode_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): Linear(in_features=800, out_features=800, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=800, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=1024, out_features=800, bias=True)\n",
      "    (norm1): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (trans_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=800, out_features=800, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=800, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=800, bias=True)\n",
      "        (norm1): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=800, out_features=800, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=800, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=800, bias=True)\n",
      "        (norm1): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((800,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm1): LSTM(800, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings=10002,\n",
    "                                  embedding_dim=800)\n",
    "        self.encode_layer = nn.TransformerEncoderLayer(d_model=800,\n",
    "                                                       nhead=8,\n",
    "                                                       dim_feedforward=1024,\n",
    "                                                       dropout=0.1,\n",
    "                                                       activation='relu')\n",
    "        self.trans_encoder = nn.TransformerEncoder(self.encode_layer,\n",
    "                                                   num_layers=2)\n",
    "        self.lstm1 = nn.LSTM(input_size=800,\n",
    "                            hidden_size=128,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc1 = nn.Linear(128*2,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        x = self.trans_encoder(x)\n",
    "        r_out, (h_n, h_c) = self.lstm1(x)\n",
    "        x = r_out[:,-1,:]\n",
    "        x = self.fc1(x)\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        return(x)\n",
    "    \n",
    "model = Transformer()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): Embedding(10002, 50)\n",
      "  (lstm1): LSTM(50, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings=10002,\n",
    "                                  embedding_dim=50)\n",
    "        self.lstm1 = nn.LSTM(input_size=50,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False)\n",
    "        self.fc1 = nn.Linear(64,10)\n",
    "        self.fc2 = nn.Linear(10,2)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        r_out, (h_n, h_c) = self.lstm1(x,None)\n",
    "        x = r_out[:,-1,:]\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.log_softmax(x,dim=1)\n",
    "        return(x)\n",
    "    \n",
    "model = Transformer()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 530,468 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_accuracy(probs,all_labels):\n",
    "    def getClass(x):\n",
    "        return(x.index(max(x)))\n",
    "    \n",
    "    all_labels = all_labels.tolist()\n",
    "    probs = pd.Series(probs.tolist())\n",
    "    all_predicted = probs.apply(getClass)\n",
    "    all_predicted.reset_index(drop=True, inplace=True)\n",
    "    vc = pd.value_counts(all_predicted == all_labels)\n",
    "    try:\n",
    "        acc = vc[1]/len(all_labels)\n",
    "    except:\n",
    "        if(vc.index[0]==False):\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = 1\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define optimizer\n",
    "#optimizer = SGD(model.parameters(), lr = 0.01, momentum = 0)\n",
    "optimizer = Adam(model.parameters(), lr = 0.01, eps=1)\n",
    "\n",
    "## Define loss function\n",
    "#criterion = nn.BCELoss().to(device) ## Sigmoid activation function\n",
    "#criterion = nn.NLLLoss().to(device) ### Log_softmax activation\n",
    "criterion = nn.CrossEntropyLoss().to(device) ## No activation function bcs softmax included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training acc: 0.498787 -Training loss: 0.693005 - Val acc: 0.500000 - Val loss: 0.692872 - Time: 140.5435s\n",
      "Epoch 2 - Training acc: 0.503212 -Training loss: 0.692962 - Val acc: 0.500000 - Val loss: 0.692848 - Time: 136.8893s\n",
      "Epoch 3 - Training acc: 0.499412 -Training loss: 0.692954 - Val acc: 0.503857 - Val loss: 0.692806 - Time: 137.7879s\n",
      "Epoch 4 - Training acc: 0.503587 -Training loss: 0.692957 - Val acc: 0.500000 - Val loss: 0.692897 - Time: 140.7704s\n",
      "Epoch 5 - Training acc: 0.498738 -Training loss: 0.692962 - Val acc: 0.500000 - Val loss: 0.692784 - Time: 137.5566s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-75cc790ac333>\", line 14, in <module>\n",
      "    loss.backward()\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\hazim\\anaconda3\\envs\\pytorch\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    timer = time.time()\n",
    "\n",
    "    for batch in train_iterator:\n",
    "        batch.codes = batch.codes.to(device)\n",
    "        batch.label = batch.label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.codes)\n",
    "        loss = criterion(output, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = softmax_accuracy(output,batch.label)\n",
    "        running_acc += acc.item()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            running_acc_val = 0\n",
    "            running_loss_val = 0\n",
    "            for batch in valid_iterator:\n",
    "                batch.codes = batch.codes.to(device)\n",
    "                batch.label = batch.label.to(device)\n",
    "                output_val = model(batch.codes)\n",
    "                loss_val = criterion(output_val,batch.label)\n",
    "                acc_val = softmax_accuracy(output_val,batch.label)\n",
    "                running_acc_val += acc_val.item()\n",
    "                running_loss_val += loss_val.item()\n",
    "        \n",
    "        print(\"Epoch {} - Training acc: {:.6f} -Training loss: {:.6f} - Val acc: {:.6f} - Val loss: {:.6f} - Time: {:.4f}s\".format(e+1, running_acc/len(train_iterator), running_loss/len(train_iterator), running_acc_val/len(valid_iterator), running_loss_val/len(valid_iterator), (time.time()-timer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SOFTMAX\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_acc_test = 0\n",
    "    running_loss_test = 0\n",
    "    all_pred=[]\n",
    "    all_labels=[]\n",
    "    for batch in test_iterator:\n",
    "        batch.codes = batch.codes.to(device)\n",
    "        batch.label = batch.label.to(device)\n",
    "        output_test = model(batch.codes).squeeze(1)\n",
    "        loss_test = criterion(output_test,batch.label)\n",
    "        acc_test = softmax_accuracy(output_test,batch.label)\n",
    "        running_acc_test += acc_test.item()\n",
    "        running_loss_test += loss_test.item()\n",
    "        all_pred += output_test.tolist()\n",
    "        all_labels += batch.label.tolist()\n",
    "\n",
    "\n",
    "print('Test acc: ',running_acc_test/len(test_iterator))\n",
    "print('Test loss: ',running_loss_test/len(test_iterator))\n",
    "\n",
    "\n",
    "def getClass(x):\n",
    "    return(x.index(max(x)))\n",
    "\n",
    "probs = pd.Series(all_pred)\n",
    "all_predicted = probs.apply(getClass)\n",
    "all_predicted.reset_index(drop=True, inplace=True)\n",
    "vc = pd.value_counts(all_predicted == all_labels)\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_predicted)\n",
    "print('Confusion matrix: \\n',confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BINARY\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_acc_test = 0\n",
    "    running_loss_test = 0\n",
    "    all_pred=[]\n",
    "    all_labels=[]\n",
    "    for batch in test_iterator:\n",
    "        batch.codes = batch.codes.to(device)\n",
    "        batch.label = batch.label.to(device)\n",
    "        output_test = model(batch.codes).squeeze(1)\n",
    "        loss_test = criterion(output_test,batch.label)\n",
    "        acc_test = binary_accuracy(output_test,batch.label)\n",
    "        running_acc_test += acc_test.item()\n",
    "        running_loss_test += loss_test.item()\n",
    "        all_pred += torch.round(output_test).tolist()\n",
    "        all_labels += batch.label.tolist()\n",
    "\n",
    "\n",
    "print('Test acc: ',running_acc_test/len(test_iterator))\n",
    "print('Test loss: ',running_loss_test/len(test_iterator))\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_pred)\n",
    "print('Confusion matrix: \\n',confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
