{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output from Transformer + LSTM into Random Forest ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../X_train.pkl')\n",
    "X_test = pd.read_pickle('../X_test.pkl')\n",
    "y_train = pd.read_pickle('../y_train.pkl')\n",
    "y_test = pd.read_pickle('../y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[1:,:]\n",
    "X_test = X_test.iloc[1:,:]\n",
    "y_train = y_train.iloc[1:]\n",
    "y_test = y_test.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(y_train[0])\n",
    "y_test = list(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['label']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = X_train[X_train.label==1]\n",
    "false = X_train[X_train.label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = false[0:20000].append(true[0:1333])\n",
    "test  = false[20000:22494].append(true[2000:2166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:-1]\n",
    "X_test = test.iloc[:,:-1]\n",
    "y_train = list(train.iloc[:,-1])\n",
    "y_test = list(test.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.533325  , 8.00187547])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=[0.0,1.0],y=y_train)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.469030711337703"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0.0: 0.533325, 1.0: 8.001875468867217},\n",
       "                       criterion='gini', max_depth=None, max_features=128,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0.0:weights[0], 1.0:weights[1]}, oob_score=True, max_features=128, n_jobs=-1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999062485351333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_train)\n",
    "output_prob = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[20000     0]\n",
      " [    2  1331]]\n",
      "\n",
      "TP: 1331\n",
      "FP: 0\n",
      "TN: 20000\n",
      "FN: 2\n",
      "\n",
      "Accuracy: 0.9999062485351333\n",
      "Precision: 1.0\n",
      "Recall: 0.9984996249062266\n",
      "F-measure: 0.9992492492492493\n",
      "Area Under the Curve: 1.0\n",
      "Precision-Recall AUC: 1.0\n",
      "Matthew Correlation Coefficient: 0.9991995721214725\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_train, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_train, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_train, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_train, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_train, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_train, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test)\n",
    "output_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[2494    0]\n",
      " [ 166    0]]\n",
      "\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 2494\n",
      "FN: 166\n",
      "\n",
      "Accuracy: 0.937593984962406\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F-measure: 0.0\n",
      "Area Under the Curve: 0.47614395029999707\n",
      "Precision-Recall AUC: 0.061449449253679594\n",
      "Matthew Correlation Coefficient: 0.0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_test, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_test, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_test, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_test, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_test, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_test, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
