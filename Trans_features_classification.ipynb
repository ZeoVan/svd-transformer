{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output from Transformer + LSTM into Random Forest ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../X_train.pkl')\n",
    "X_test = pd.read_pickle('../X_test.pkl')\n",
    "y_train = pd.read_pickle('../y_train.pkl')\n",
    "y_test = pd.read_pickle('../y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[1:,:]\n",
    "X_test = X_test.iloc[1:,:]\n",
    "y_train = y_train.iloc[1:]\n",
    "y_test = y_test.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(y_train[0])\n",
    "y_test = list(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['label']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['label']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = X_train[X_train.label==1]\n",
    "false = X_train[X_train.label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = false[0:20000].append(true[0:1333])\n",
    "test  = false[20000:22494].append(true[2000:2166])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:-1]\n",
    "X_test = test.iloc[:,:-1]\n",
    "y_train = list(train.iloc[:,-1])\n",
    "y_test = list(test.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.533325  , 8.00187547])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=[0.0,1.0],y=y_train)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0.0: 0.533325, 1.0: 8.001875468867217},\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0.0:weights[0], 1.0:weights[1]}, oob_score=True, n_jobs=-1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999531242675667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(model)\n",
    "sel = sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight={0:1, 1:5.5}, oob_score=True, n_jobs=-1,n_estimators=500,criterion='gini')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(loss='deviance', learning_rate=1,n_estimators=300, random_state=1234, max_depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_train)\n",
    "output_prob = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[18959  1041]\n",
      " [  238  1095]]\n",
      "\n",
      "TP: 1095\n",
      "FP: 1041\n",
      "TN: 18959\n",
      "FN: 238\n",
      "\n",
      "Accuracy: 0.9400459382177847\n",
      "Precision: 0.5126404494382022\n",
      "Recall: 0.8214553638409603\n",
      "F-measure: 0.6313058518304987\n",
      "Area Under the Curve: 0.951338728432108\n",
      "Precision-Recall AUC: 0.4674908371116769\n",
      "Matthew Correlation Coefficient: 0.6203945522075344\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_train, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_train, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_train, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_train, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_train, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_train, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test)\n",
    "output_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[2344  150]\n",
      " [  45  121]]\n",
      "\n",
      "TP: 121\n",
      "FP: 150\n",
      "TN: 2344\n",
      "FN: 45\n",
      "\n",
      "Accuracy: 0.9266917293233082\n",
      "Precision: 0.44649446494464945\n",
      "Recall: 0.7289156626506024\n",
      "F-measure: 0.5537757437070938\n",
      "Area Under the Curve: 0.8768393542091379\n",
      "Precision-Recall AUC: 0.3869063837409769\n",
      "Matthew Correlation Coefficient: 0.534794812673835\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_test, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_test, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_test, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_test, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_test, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_test, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate=1,n_estimators=300\n",
    "Confusion matrix: \n",
    " [[2347  147]\n",
    " [  46  120]]\n",
    "\n",
    "TP: 120\n",
    "FP: 147\n",
    "TN: 2347\n",
    "FN: 46\n",
    "\n",
    "Accuracy: 0.9274436090225564\n",
    "Precision: 0.449438202247191\n",
    "Recall: 0.7228915662650602\n",
    "F-measure: 0.5542725173210162\n",
    "Area Under the Curve: 0.8812185389513145\n",
    "Precision-Recall AUC: 0.39039287153076524\n",
    "Matthew Correlation Coefficient: 0.5344544945611271\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boost (XGBOOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(learning_rate=0.05, n_jobs=-1, random_state =1234, objective='binary:logistic',\n",
    "                          eval_metric='auc', num_boost_round=10, max_depth=6, booster='gbtree',\n",
    "                         importance_type ='gain',reg_alpha=0.3, reg_lambda=1,base_score=0.5, n_estimators=100,\n",
    "                         gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_train)\n",
    "output_prob = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[937174  16393]\n",
      " [ 38949  26955]]\n",
      "\n",
      "TP: 26955\n",
      "FP: 16393\n",
      "TN: 937174\n",
      "FN: 38949\n",
      "\n",
      "Accuracy: 0.9457149835551968\n",
      "Precision: 0.6218279966780474\n",
      "Recall: 0.40900400582665697\n",
      "F-measure: 0.49344634423168454\n",
      "Area Under the Curve: 0.9386740392303465\n",
      "Precision-Recall AUC: 0.571352036552205\n",
      "Matthew Correlation Coefficient: 0.4774998828162578\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_train, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_train, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_train, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_train, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_train, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_train, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_train, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test)\n",
    "output_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[116838   2328]\n",
      " [  5177   3076]]\n",
      "\n",
      "TP: 3076\n",
      "FP: 2328\n",
      "TN: 116838\n",
      "FN: 5177\n",
      "\n",
      "Accuracy: 0.9410998359742268\n",
      "Precision: 0.5692079940784603\n",
      "Recall: 0.3727129528656246\n",
      "F-measure: 0.45046496302262573\n",
      "Area Under the Curve: 0.9109861921752845\n",
      "Precision-Recall AUC: 0.49956204527735787\n",
      "Matthew Correlation Coefficient: 0.43133078398377234\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_true=y_test, y_pred=output)\n",
    "print('Confusion matrix: \\n',confusion)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print('\\nTP:',tp)\n",
    "print('FP:',fp)\n",
    "print('TN:',tn)\n",
    "print('FN:',fn)\n",
    "\n",
    "## Performance measure\n",
    "print('\\nAccuracy: '+ str(metrics.accuracy_score(y_true=y_test, y_pred=output)))\n",
    "print('Precision: '+ str(metrics.precision_score(y_true=y_test, y_pred=output)))\n",
    "print('Recall: '+ str(metrics.recall_score(y_true=y_test, y_pred=output)))\n",
    "print('F-measure: '+ str(metrics.f1_score(y_true=y_test, y_pred=output)))\n",
    "print('Area Under the Curve: '+ str(metrics.roc_auc_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Precision-Recall AUC: '+ str(metrics.average_precision_score(y_true=y_test, y_score=output_prob[:,1])))\n",
    "print('Matthew Correlation Coefficient: '+ str(metrics.matthews_corrcoef(y_true=y_test, y_pred=output)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
