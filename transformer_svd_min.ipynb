{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Transformers!\n",
    "\n",
    "### Attention is all you need \n",
    "(https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "### For software vulnerability detection GYM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a minimal example of this **CRAZY** idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSTM is working with:\n",
    "    * Adam LR = 0.01\n",
    "    * Overfitted on 14 epoch. 100% training accuracy.\n",
    "    * Worked on 1K dataset sample\n",
    "    * Using the `hidden`n or `cell` output from LSTM. Not the `output`.\n",
    "    * Bidrectional (2 layers)\n",
    "* Transformer:\n",
    "    * Still trying to find the right combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.optim import SGD,Adam\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import torchtext.vocab as vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "#device = torch.device(\"cpu\");\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load playset dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('playset(0.25.2).pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93792</th>\n",
       "      <td>go_file_opener_open (GOFileOpener const *fo, g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79770</th>\n",
       "      <td>updatePathMap(bool left_level) {\\n\\tPoint from...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66999</th>\n",
       "      <td>interpret_tilde(const char* path) {\\n    stati...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44284</th>\n",
       "      <td>checkVarExp(\\n        Absyn *node,\\n        Ta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49515</th>\n",
       "      <td>will_have_skip_worktree(const struct cache_ent...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96701</th>\n",
       "      <td>AVLTree_insert(AVLTree * tree, void * data)\\n{...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67815</th>\n",
       "      <td>remove_hook(const char *name, hookfn fn)\\n{\\n\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88363</th>\n",
       "      <td>output_def(dico_stream_t str, struct gcide_db ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65929</th>\n",
       "      <td>getState(\\n\\t\\tFLMUINT\\t\\tuiFieldID)\\n\\t{\\n\\t\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16426</th>\n",
       "      <td>untag_proplist(Pulse_Tag *tag, Eina_Hash **pro...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          functionSource  combine\n",
       "93792  go_file_opener_open (GOFileOpener const *fo, g...    False\n",
       "79770  updatePathMap(bool left_level) {\\n\\tPoint from...    False\n",
       "66999  interpret_tilde(const char* path) {\\n    stati...    False\n",
       "44284  checkVarExp(\\n        Absyn *node,\\n        Ta...     True\n",
       "49515  will_have_skip_worktree(const struct cache_ent...     True\n",
       "...                                                  ...      ...\n",
       "96701  AVLTree_insert(AVLTree * tree, void * data)\\n{...    False\n",
       "67815  remove_hook(const char *name, hookfn fn)\\n{\\n\\...    False\n",
       "88363  output_def(dico_stream_t str, struct gcide_db ...    False\n",
       "65929  getState(\\n\\t\\tFLMUINT\\t\\tuiFieldID)\\n\\t{\\n\\t\\...    False\n",
       "16426  untag_proplist(Pulse_Tag *tag, Eina_Hash **pro...     True\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionSource</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>v_identifier(void)\\n#else\\nv_identifier()\\n#en...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           functionSource combine\n",
       "count                                              100000  100000\n",
       "unique                                             100000       2\n",
       "top     v_identifier(void)\\n#else\\nv_identifier()\\n#en...    True\n",
       "freq                                                    1   50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkCapture2() const\\n{\\n    for(int i=6;i<48;i++)\\n    {\\n        switch(board[i])\\n        {\\n        case MAN2:\\n            if(board[i+5]==MAN1 || board[i+5]==KING1)\\n                if(board[i+10]==FREE) return true;\\n            if(board[i+6]==MAN1 || board[i+6]==KING1)\\n                if(board[i+12]==FREE) return true;\\n            break;\\n        case KING2:\\n            if(board[i-6]==MAN1 || board[i-6]==KING1)\\n                if(board[i-12]==FREE) return true;\\n            if(board[i-5]==MAN1 || board[i-5]==KING1)\\n                if(board[i-10]==FREE) return true;\\n            if(board[i+5]==MAN1 || board[i+5]==KING1)\\n                if(board[i+10]==FREE) return true;\\n            if(board[i+6]==MAN1 || board[i+6]==KING1)\\n                if(board[i+12]==FREE) return true;\\n        }\\n    }\\n    return false;\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.functionSource[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data (in JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(code):\n",
    "    ## Remove newlines & tabs\n",
    "    code = re.sub('(\\n)|(\\\\\\\\n)|(\\\\\\\\)|(\\\\t)|(/)|(\\\\r)|(\\\")|(\\')','',code)\n",
    "    ## Remove code comments\n",
    "    code = re.sub(r'/\\*(.|[\\r\\n])*?\\*/','',code)\n",
    "    ## Mix split (characters and words)\n",
    "    splitter = ' +|(;)|(\\()|(==)|(\\))|(=)|(\\+)|(\\-)|(\\[)|(\\])|(<)|(>)|({)|(#)'\n",
    "    code = re.split(splitter,code)\n",
    "    ## Remove None type\n",
    "    code = list(filter(None, code))\n",
    "    code = list(filter(str.strip, code))\n",
    "    code = \" \".join(code)\n",
    "    ## Return list of tokens\n",
    "    return(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the codes\n",
    "dataset.functionSource = dataset.functionSource.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change labels boolean to 1 and 0\n",
    "dataset.iloc[:,1] = np.multiply(dataset.iloc[:,1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change column name\n",
    "dataset = dataset.rename(columns={'functionSource':'codes', 'combine':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CardPowerOff ( reader* globalData, char socket ) { char cmd [ 4 ] , ack ; int retVal, actual, retryTimes = 2 ; # ifdef ASE_DEBUG syslog ( LOG_INFO, CardPowerOff - Enter ) ; # endif if ( ( retVal = cardCommandInit ( globalData, socket, 1 ) ) ) return retVal ; cmd [ 0 ] = ASE_PACKET_TYPE ( 0x50, globalData - > commandCounter, socket ) ; globalData - > commandCounter + + ; globalData - > commandCounter % = 4 ; cmd [ 1 ] = 0x21 ; cmd [ 2 ] = 0x0 ; cmd [ 3 ] = cmd [ 0 ] ^ cmd [ 1 ] ^ cmd [ 2 ] ; do { lock_mutex ( globalData ) ; retVal = sendControlCommand ( globalData, socket, cmd, 4, &ack, &actual, 0 ) ; unlock_mutex ( globalData ) ; retryTimes - - ; } while ( retVal ! = ASE_OK && retryTimes ) ; if during the 3 tries the command failed, return an error status if ( retVal < 0 ) { return retVal ; } if ( ack ! = 0x20 ) { return parseStatus ( ack ) ; } * if the card is present, change the status to powered off * if ( globalData - > cards [ ( int ) socket ] .status ) globalData - > cards [ ( int ) socket ] .status = 1 ; # ifdef ASE_DEBUG syslog ( LOG_INFO, CardPowerOff - Exit ) ; # endif return ASE_OK ; }'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.codes[24492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "false = dataset[dataset.iloc[:,1]==0]\n",
    "true = dataset[dataset.iloc[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split to train,test,valid\n",
    "train = false[0:400].append(true[0:400])\n",
    "test  = false[400:400].append(true[400:450])\n",
    "valid = false[450:500].append(true[400:500])\n",
    "\n",
    "## Shuffle\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "valid = valid.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to json\n",
    "train.to_json('.data/train_1k.json', orient='records',lines=True)\n",
    "test.to_json('.data/test_1k.json', orient='records',lines=True)\n",
    "valid.to_json('.data/valid_1k.json', orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the field\n",
    "\n",
    "CODES = torchtext.data.Field(batch_first=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.int64)\n",
    "fields = {'codes': ('codes', CODES), 'label': ('label', LABEL)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the 1K data as TabularDataset\n",
    "train_data, valid_data, test_data = torchtext.data.TabularDataset.splits(\n",
    "                                        path = '.data',\n",
    "                                        train = 'train_1k.json',\n",
    "                                        validation = 'valid_1k.json',\n",
    "                                        test = 'test_1k.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the min data as TabularDataset\n",
    "train_data, valid_data, test_data = torchtext.data.TabularDataset.splits(\n",
    "                                        path = '.data',\n",
    "                                        train = 'train_min.json',\n",
    "                                        validation = 'valid_min.json',\n",
    "                                        test = 'test_min.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the ALL data as TabularDataset\n",
    "train_data, valid_data, test_data = torchtext.data.TabularDataset.splits(\n",
    "                                        path = '.data',\n",
    "                                        train = 'train_all.json',\n",
    "                                        validation = 'valid_all.json',\n",
    "                                        test = 'test_all.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'codes': ['icalparser_get_line', '(', 'icalparser', '*parser,', 'char*', '(', '*line_gen_func', ')', '(', 'char', '*s,', 'size_t', 'size,', 'void', '*d', ')', ')', '{', 'char', '*line', ';', 'char', '*line_p', ';', 'size_t', 'buf_size', '=', 'parser', '-', '>', 'tmp_buf_size', ';', 'line_p', '=', 'line', '=', 'icalmemory_new_buffer', '(', 'buf_size', ')', ';', 'line', '[', '0', ']', '=', '0', ';', '*', 'Read', 'lines', 'by', 'calling', 'line_gen_func', 'and', 'putting', 'the', 'data', 'into', 'parser', '-', '>', 'temp.', 'If', 'the', 'line', 'is', 'a', 'continuation', 'line', '(', 'begins', 'with', 'a', 'space', 'after', 'a', 'newline', ')', 'then', 'append', 'the', 'data', 'onto', 'line', 'and', 'read', 'again.', 'Otherwise,', 'exit', 'the', 'loop.', '*', 'while', '(', '1', ')', '{', '*', 'The', 'first', 'part', 'of', 'the', 'loop', 'deals', 'with', 'the', 'temp', 'buffer,', 'which', 'was', 'read', 'on', 'he', 'last', 'pass', 'through', 'the', 'loop.', 'The', 'routine', 'is', 'split', 'like', 'this', 'because', 'it', 'has', 'to', 'read', 'lone', 'line', 'ahead', 'to', 'determine', 'if', 'a', 'line', 'is', 'a', 'continuation', 'line.', '**', 'The', 'tmp', 'buffer', 'is', 'not', 'clear,', 'so', 'transfer', 'the', 'data', 'in', 'it', 'to', 'the', 'output.', 'This', 'may', 'be', 'left', 'over', 'from', 'a', 'previous', 'call', '*if', '(', 'parser', '-', '>', 'temp', '[', '0', ']', '!', '=', '0', ')', '{', '*', 'If', 'the', 'last', 'position', 'in', 'the', 'temp', 'buffer', 'is', 'occupied,', 'mark', 'the', 'buffer', 'as', 'full.', 'The', 'means', 'we', 'will', 'do', 'another', 'read', 'later,', 'because', 'the', 'line', 'is', 'not', 'finished', '*', 'if', '(', 'parser', '-', '>', 'temp', '[', 'parser', '-', '>', 'tmp_buf_size', '-', '1', ']', '==', '0', '&&parser', '-', '>', 'temp', '[', 'parser', '-', '>', 'tmp_buf_size', '-', '2', ']', '!', '=', '&&', 'parser', '-', '>', 'temp', '[', 'parser', '-', '>', 'tmp_buf_size', '-', '2', ']', '!', '=', '0', ')', '{', 'parser', '-', '>', 'buffer_full', '=', '1', ';', '}', 'else', '{', 'parser', '-', '>', 'buffer_full', '=', '0', ';', '}', '*', 'Copy', 'the', 'temp', 'to', 'the', 'output', 'and', 'clear', 'the', 'temp', 'buffer.', '*', 'if', '(', 'parser', '-', '>', 'continuation_line', '==', '1', ')', '{', '*', 'back', 'up', 'the', 'pointer', 'to', 'erase', 'the', 'continuation', 'characters', '*', 'parser', '-', '>', 'continuation_line', '=', '0', ';', 'line_p', '-', '-', ';', 'if', '(', '*', '(', 'line_p', '-', '1', ')', '==', 'r', ')', '{', 'line_p', '-', '-', ';', '}', '*', 'copy', 'one', 'space', 'up', 'to', 'eliminate', 'the', 'leading', 'space*', 'icalmemory_append_string', '(', '&line,&line_p,&buf_size,', 'parser', '-', '>', 'temp', '+', '1', ')', ';', '}', 'else', '{', 'icalmemory_append_string', '(', '&line,&line_p,&buf_size,parser', '-', '>', 'temp', ')', ';', '}', 'parser', '-', '>', 'temp', '[', '0', ']', '=', '0', ';', '}parser', '-', '>', 'temp', '[', 'parser', '-', '>', 'tmp_buf_size', '-', '1', ']', '=', '1', ';', '*', 'Mark', 'end', 'of', 'buffer', '*', '******', 'Here', 'is', 'where', 'the', 'routine', 'gets', 'string', 'data', '******************if', '(', '(', '*line_gen_func', ')', '(', 'parser', '-', '>', 'temp,parser', '-', '>', 'tmp_buf_size,parser', '-', '>', 'line_gen_data', ')', '==', '0', ')', '{', '*', 'Get', 'more', 'data', '*', '*', 'If', 'the', 'first', 'position', 'is', 'clear,', 'it', 'means', 'we', 'didnt', 'get', 'any', 'more', 'data', 'from', 'the', 'last', 'call', 'to', 'line_ge_func*', 'if', '(', 'parser', '-', '>', 'temp', '[', '0', ']', '==', '0', ')', '{', 'if', '(', 'line', '[', '0', ']', '!', '=', '0', ')', '{', '*', 'There', 'is', 'data', 'in', 'the', 'output,', 'so', 'fall', 'trhough', 'and', 'process', 'it*', 'break', ';', '}', 'else', '{', '*', 'No', 'data', 'in', 'output', ';', 'return', 'and', 'signal', 'that', 'there', 'is', 'no', 'more', 'input*', 'free', '(', 'line', ')', ';', 'return', '0', ';', '}', '}}', '*', 'If', 'the', 'output', 'line', 'ends', 'in', 'a', 'and', 'the', 'temp', 'buffer', 'begins', 'with', 'a', 'or', 'tab,', 'then', 'the', 'buffer', 'holds', 'a', 'continuation', 'line,', 'so', 'keep', 'reading.', 'RFC', '2445,', 'section', '4.1', '*if', '(', 'line_p', '>', 'line', '+', '1', '&&', '*', '(', 'line_p', '-', '1', ')', '==', '&&', '(', 'parser', '-', '>', 'temp', '[', '0', ']', '==', '||', 'parser', '-', '>', 'temp', '[', '0', ']', '==', 't', ')', ')', '{', 'parser', '-', '>', 'continuation_line', '=', '1', ';', '}', 'else', 'if', '(', 'parser', '-', '>', 'buffer_full', '==', '1', ')', '{', '*', 'The', 'buffer', 'was', 'filled', 'on', 'the', 'last', 'read,', 'so', 'read', 'again', '*}', 'else', '{', '*', 'Looks', 'like', 'the', 'end', 'of', 'this', 'content', 'line,', 'so', 'break', '*', 'break', ';', '}', '}', '*', 'Erase', 'the', 'final', 'newline', 'andor', 'carriage', 'return*', 'if', '(', 'line_p', '>', 'line', '+', '1', '&&', '*', '(', 'line_p', '-', '1', ')', '==', ')', '{', '*', '(', 'line_p', '-', '1', ')', '=', '0', ';', 'if', '(', '*', '(', 'line_p', '-', '2', ')', '==', 'r', ')', '{', '*', '(', 'line_p', '-', '2', ')', '=', '0', ';', '}', '}', 'else', '{', '*', '(', 'line_p', ')', '=', '0', ';', '}while', '(', '(', '*line_p', '==', '0', '||', 'iswspace', '(', '*line_p', ')', ')', '&&', 'line_p', '>', 'line', ')', '{', '*line_p', '=', '0', ';', 'line_p', '-', '-', ';', '}', 'return', 'line', ';', '}'], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "print(vars(valid_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doneeeeeeeeeeeeeeeee !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary-related preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Build the vocabulary\n",
    "\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "CODES.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 10002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(CODES.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', 14063), (')', 14060), (';', 13060), ('-', 6902), ('=', 6370), ('>', 4926), ('{', 3205), ('*', 2803), ('if', 2626), ('}', 2099), ('0', 2017), ('+', 1935), ('[', 1827), (']', 1824), ('return', 1450), ('i', 1170), ('1', 1117), ('<', 1031), ('==', 993), ('int', 882), ('the', 847), ('NULL', 776), (',', 728), ('char', 655), ('!', 580), ('for', 532), ('else', 524), ('#', 524), ('struct', 523), ('to', 443), ('const', 403), ('case', 371), ('&&', 356), ('a', 346), ('sizeof', 333), ('break', 324), ('ret', 317), ('p', 284), ('of', 269), ('||', 251), ('is', 251), ('len', 241), ('in', 235), ('unsigned', 231), ('&', 221), ('2', 217), ('this', 207), ('data', 201), ('buf', 188), ('size', 186), ('%s', 183), ('we', 175), (':', 175), ('not', 172), ('and', 169), ('while', 166), ('%s,', 165), ('0,', 164), ('name', 163), ('void', 158), ('}}', 153), ('error', 147), ('type', 145), ('fprintf', 143), ('it', 143), ('file', 142), ('n', 136), ('goto', 134), ('f', 134), ('be', 133), ('result', 127), ('1,', 122), ('c', 121), ('s', 120), ('4', 117), ('offset', 117), ('j', 115), ('priv', 115), ('*if', 114), ('next', 112), ('}if', 111), ('3', 110), ('r', 110), ('buf,', 110), ('val', 104), ('value', 104), ('size_t', 104), ('name,', 103), ('err', 103), ('strlen', 102), ('out', 100), ('str', 100), ('b', 98), ('|', 98), ('?', 98), ('%d', 97), ('long', 91), ('NULL,', 91), ('x', 91), ('l', 91)]\n"
     ]
    }
   ],
   "source": [
    "## Most common word\n",
    "print(CODES.vocab.freqs.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '(', ')', ';', '-', '=', '>', '{', '*']\n",
      "defaultdict(None, {0: 0, 1: 1})\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(CODES.vocab.itos[:10])\n",
    "print(LABEL.vocab.stoi)\n",
    "print(CODES.vocab.stoi[CODES.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## place into iterators\n",
    "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = 64,\n",
    "    sort = False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Word2Vec (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_json('.data/train.json',orient='records',lines=True)\n",
    "\n",
    "w2v = Word2Vec(corpus.codes, size=300, workers=16, sg=1, min_count=3)\n",
    "w2v.save('.data/node_w2v_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04268723, -0.01990928, -0.10372822, ...,  0.34928635,\n",
       "        -0.24622028, -0.02363101],\n",
       "       [ 0.06655177, -0.08706249, -0.11346684, ...,  0.2967248 ,\n",
       "        -0.16500187, -0.10260527],\n",
       "       [ 0.10059763, -0.0993171 , -0.14234892, ...,  0.3913037 ,\n",
       "        -0.22237949,  0.02339004],\n",
       "       ...,\n",
       "       [-0.0031671 ,  0.01939397, -0.00094254, ..., -0.06062187,\n",
       "        -0.0873417 ,  0.10190531],\n",
       "       [-0.03719744,  0.02801778,  0.02174594, ..., -0.05577604,\n",
       "        -0.07265704, -0.00079473],\n",
       "       [ 0.01092949, -0.03061507, -0.045645  , ..., -0.06999503,\n",
       "        -0.15679213,  0.11291362]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = Word2Vec.load('.data/node_w2v_128')\n",
    "w2v.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer class (with LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): Embedding(10002, 104)\n",
      "  (encode_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): Linear(in_features=104, out_features=104, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=104, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=1024, out_features=104, bias=True)\n",
      "    (norm1): LayerNorm((104,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((104,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (trans_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=104, out_features=104, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=104, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=104, bias=True)\n",
      "        (norm1): LayerNorm((104,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((104,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm1): LSTM(104, 104, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=208, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings=10002,\n",
    "                                  embedding_dim=104)\n",
    "        self.encode_layer = nn.TransformerEncoderLayer(d_model=104,\n",
    "                                                       nhead=8,\n",
    "                                                       dim_feedforward=1024,\n",
    "                                                       dropout=0.1,\n",
    "                                                       activation='relu')\n",
    "        self.trans_encoder = nn.TransformerEncoder(self.encode_layer,\n",
    "                                                   num_layers=1)\n",
    "        self.lstm1 = nn.LSTM(input_size=104,\n",
    "                            hidden_size=104,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(104*2,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        x = self.trans_encoder(x)\n",
    "        output, (hidden, cell) = self.lstm1(x)\n",
    "        x = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        x = self.fc1(x)\n",
    "        return(x)\n",
    "    \n",
    "model = Transformer()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embed): Embedding(10002, 150)\n",
      "  (lstm1): LSTM(150, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "global k\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM,self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=10002,\n",
    "                                  embedding_dim=150)\n",
    "        global k\n",
    "        k = self.embed\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=150,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        #self.fc1 = nn.Linear(128,64)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(64*2,2)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        output, (hidden, cell) = self.lstm1(x)\n",
    "        #x = output[:,-1,:]\n",
    "        x = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        #x =self.dropout(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1))\n",
    "        #x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.log_softmax(x,dim=1)\n",
    "        return(x)\n",
    "    \n",
    "model = LSTM()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embed): Embedding(10002, 128)\n",
      "  (cnn1): Conv2d(1, 20, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (cnn2): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (cnn3): Conv2d(1, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=60, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_embeddings=10002,\n",
    "                                  embedding_dim=128)\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,\n",
    "                              out_channels=20,\n",
    "                              kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=1,\n",
    "                              out_channels=20,\n",
    "                              kernel_size=3)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=1,\n",
    "                              out_channels=20,\n",
    "                              kernel_size=4)\n",
    "        self.fc1 = nn.Linear(60,2)\n",
    "        #self.fc2 = nn.Linear(30,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.embed(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x1 = F.relu(self.cnn1(x))\n",
    "        x1 = F.max_pool2d(x1,2)\n",
    "        x1 = torch.flatten(x1,start_dim=1)\n",
    "        \n",
    "        x2 = F.relu(self.cnn2(x))\n",
    "        x2 = F.max_pool2d(x2,3)\n",
    "        x2 = torch.flatten(x2,start_dim=1)\n",
    "        \n",
    "        x3 = F.relu(self.cnn3(x))\n",
    "        x3 = F.max_pool2d(x3,4)\n",
    "        x3 = torch.flatten(x3,start_dim=1)\n",
    "        \n",
    "        x = torch.cat((x1,x2,x3), dim=1)\n",
    "        self.fc1 = nn.Linear(x.shape[1],2)\n",
    "        x = self.fc1(x.to(device))\n",
    "        return(x)\n",
    "    \n",
    "model = CNN()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Word2Vec weights to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(w2v.wv.vectors)\n",
    "weights = weights.to(device)\n",
    "model.embed = model.embed.from_pretrained(weights)\n",
    "#model.embed = model.embed.weight.data.copy_(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,710,478 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_accuracy(probs,all_labels):\n",
    "    def getClass(x):\n",
    "        return(x.index(max(x)))\n",
    "    \n",
    "    all_labels = all_labels.tolist()\n",
    "    probs = pd.Series(probs.tolist())\n",
    "    all_predicted = probs.apply(getClass)\n",
    "    all_predicted.reset_index(drop=True, inplace=True)\n",
    "    vc = pd.value_counts(all_predicted == all_labels)\n",
    "    try:\n",
    "        acc = vc[1]/len(all_labels)\n",
    "    except:\n",
    "        if(vc.index[0]==False):\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = 1\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define optimizer\n",
    "#optimizer = SGD(model.parameters(), lr = 0.01)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "## Define loss function\n",
    "#criterion = nn.BCELoss().to(device) ## Sigmoid activation function\n",
    "#criterion = nn.NLLLoss().to(device) ### Log_softmax activation\n",
    "criterion = nn.CrossEntropyLoss().to(device) ## No activation function bcs softmax included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    timer = time.time()\n",
    "\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.codes)\n",
    "        loss = criterion(output, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = softmax_accuracy(output,batch.label)\n",
    "        running_acc += acc.item()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            running_acc_val = 0\n",
    "            running_loss_val = 0\n",
    "            for batch in valid_iterator:\n",
    "                output_val = model(batch.codes)\n",
    "                loss_val = criterion(output_val,batch.label)\n",
    "                acc_val = softmax_accuracy(output_val,batch.label)\n",
    "                running_acc_val += acc_val.item()\n",
    "                running_loss_val += loss_val.item()\n",
    "        \n",
    "        print(\"Epoch {} - Training acc: {:.6f} -Training loss: {:.6f} - Val acc: {:.6f} - Val loss: {:.6f} - Time: {:.4f}s\".format(e+1, running_acc/len(train_iterator), running_loss/len(train_iterator), running_acc_val/len(valid_iterator), running_loss_val/len(valid_iterator), (time.time()-timer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  1.0\n",
      "Train loss:  0.002189714891406206\n",
      "Confusion matrix: \n",
      " [[400   0]\n",
      " [  0 400]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    running_acc_test = 0\n",
    "    running_loss_test = 0\n",
    "    all_pred=[]\n",
    "    all_labels=[]\n",
    "    for batch in train_iterator:\n",
    "        output_test = model(batch.codes).squeeze(1)\n",
    "        loss_test = criterion(output_test,batch.label)\n",
    "        acc_test = softmax_accuracy(output_test,batch.label)\n",
    "        running_acc_test += acc_test.item()\n",
    "        running_loss_test += loss_test.item()\n",
    "        all_pred += output_test.tolist()\n",
    "        all_labels += batch.label.tolist()\n",
    "\n",
    "\n",
    "print('Train acc: ',running_acc_test/len(train_iterator))\n",
    "print('Train loss: ',running_loss_test/len(train_iterator))\n",
    "\n",
    "\n",
    "def getClass(x):\n",
    "    return(x.index(max(x)))\n",
    "\n",
    "probs = pd.Series(all_pred)\n",
    "all_predicted = probs.apply(getClass)\n",
    "all_predicted.reset_index(drop=True, inplace=True)\n",
    "vc = pd.value_counts(all_predicted == all_labels)\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_predicted)\n",
    "print('Confusion matrix: \\n',confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc:  0.46\n",
      "Test loss:  2.782841444015503\n",
      "Confusion matrix: \n",
      " [[ 0  0]\n",
      " [27 23]]\n"
     ]
    }
   ],
   "source": [
    "### SOFTMAX\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    running_acc_test = 0\n",
    "    running_loss_test = 0\n",
    "    all_pred=[]\n",
    "    all_labels=[]\n",
    "    for batch in test_iterator:\n",
    "        output_test = model(batch.codes).squeeze(1)\n",
    "        loss_test = criterion(output_test,batch.label)\n",
    "        acc_test = softmax_accuracy(output_test,batch.label)\n",
    "        running_acc_test += acc_test.item()\n",
    "        running_loss_test += loss_test.item()\n",
    "        all_pred += output_test.tolist()\n",
    "        all_labels += batch.label.tolist()\n",
    "\n",
    "\n",
    "print('Test acc: ',running_acc_test/len(test_iterator))\n",
    "print('Test loss: ',running_loss_test/len(test_iterator))\n",
    "\n",
    "\n",
    "def getClass(x):\n",
    "    return(x.index(max(x)))\n",
    "\n",
    "probs = pd.Series(all_pred)\n",
    "all_predicted = probs.apply(getClass)\n",
    "all_predicted.reset_index(drop=True, inplace=True)\n",
    "vc = pd.value_counts(all_predicted == all_labels)\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_predicted)\n",
    "print('Confusion matrix: \\n',confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BINARY\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_acc_test = 0\n",
    "    running_loss_test = 0\n",
    "    all_pred=[]\n",
    "    all_labels=[]\n",
    "    for batch in test_iterator:\n",
    "        batch.codes = batch.codes.to(device)\n",
    "        batch.label = batch.label.to(device)\n",
    "        output_test = model(batch.codes).squeeze(1)\n",
    "        loss_test = criterion(output_test,batch.label)\n",
    "        acc_test = binary_accuracy(output_test,batch.label)\n",
    "        running_acc_test += acc_test.item()\n",
    "        running_loss_test += loss_test.item()\n",
    "        all_pred += torch.round(output_test).tolist()\n",
    "        all_labels += batch.label.tolist()\n",
    "\n",
    "\n",
    "print('Test acc: ',running_acc_test/len(test_iterator))\n",
    "print('Test loss: ',running_loss_test/len(test_iterator))\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_pred)\n",
    "print('Confusion matrix: \\n',confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
